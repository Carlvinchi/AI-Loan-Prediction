# -*- coding: utf-8 -*-
"""loan_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15fRo_-AN1zajTgCCGO7Lki96BjzQvUDD
"""

from joblib import dump, load
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# Naive Bayes Approach
from sklearn.naive_bayes import MultinomialNB
# Trees Approach
from sklearn.tree import DecisionTreeClassifier
# Ensemble Approach
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
#KNN Approach
from sklearn.neighbors import KNeighborsClassifier
import random

#import the data
#from google.colab import drive
#drive.mount('/content/drive')

#importing data
#train_path = '/content/drive/MyDrive/data/train.csv'
#test_path = '/content/drive/MyDrive/data/test.csv'

# data path
train_path = "./data/train.csv"

test_path =  "./data/test.csv"

train_df = pd.read_csv(train_path)

test_df = pd.read_csv(test_path)
#train_df.head

def preprocess_train_data(train_df):

  #replace all 3+ with a random number greater than 3 in the Dependents column
  

  train_df.loc[(train_df.Dependents == "3+"), 'Dependents'] = random.randint(3,9)

  #fill NaN with some values
  train_df['Gender'] = train_df['Gender'].fillna('Male')
  train_df['Married'] = train_df['Married'].fillna('No')
  train_df['Dependents'] = train_df['Dependents'].fillna(2)
  train_df['Education'] = train_df['Education'].fillna('Graduate')
  train_df['Self_Employed'] = train_df['Self_Employed'].fillna('No')
  train_df['ApplicantIncome'] = train_df['ApplicantIncome'].fillna(1560)
  train_df['CoapplicantIncome'] = train_df['CoapplicantIncome'].fillna(0.0)
  train_df['LoanAmount'] = train_df['LoanAmount'].fillna(100.0)
  train_df['Loan_Amount_Term'] = train_df['Loan_Amount_Term'].fillna(360.0)
  train_df['Credit_History'] = train_df['Credit_History'].fillna(1.0)
  train_df['Property_Area'] = train_df['Property_Area'].fillna('Urban')
  train_df['Loan_Status'] = train_df['Loan_Status'].fillna('Y')

  #train_df.head(10)

  #train_df.info()

  #change some numeric columns to integers or float types
  train_df.astype({'Dependents': 'int64','Loan_Amount_Term': 'int64','ApplicantIncome': 'float64'}).dtypes

  #replacing categorical data with numbers
  final_train_df = pd.get_dummies(data = train_df, columns =['Gender','Married','Education','Self_Employed','Property_Area'] )

  #final_train_df.head(20)

  #the Loan_Status Column is our label so we will store it separately but let work on it
  final_train_df.loc[(final_train_df.Loan_Status=='Y'), 'Loan_Status'] = 1 # replace Y with 1 
  final_train_df.loc[(final_train_df.Loan_Status=='N'), 'Loan_Status'] = 0 # replace N with 0

  final_train_df.astype({'Loan_Status': 'int64','Dependents': 'int64'}).dtypes

  return final_train_df

  #final_train_df.head(10)

def preprocess_test_data(test_df):
  #preprocessing test data
  
  test_df.head

  #replace all 3+ with a random number greater than 3 in the Dependents column

  test_df.loc[(test_df.Dependents == "3+"), 'Dependents'] = random.randint(3,9)

  #fill NaN with some values
  test_df['Gender'] = test_df['Gender'].fillna('Male')
  test_df['Married'] = test_df['Married'].fillna('No')
  test_df['Dependents'] = test_df['Dependents'].fillna(2)
  test_df['Education'] = test_df['Education'].fillna('Graduate')
  test_df['Self_Employed'] = test_df['Self_Employed'].fillna('No')
  test_df['ApplicantIncome'] = test_df['ApplicantIncome'].fillna(1560)
  test_df['CoapplicantIncome'] = test_df['CoapplicantIncome'].fillna(0.0)
  test_df['LoanAmount'] = test_df['LoanAmount'].fillna(100.0)
  test_df['Loan_Amount_Term'] = test_df['Loan_Amount_Term'].fillna(360.0)
  test_df['Credit_History'] = test_df['Credit_History'].fillna(1.0)
  test_df['Property_Area'] = test_df['Property_Area'].fillna('Urban')

  #change some numeric columns to integers or float types
  test_df.astype({'Dependents': 'int64','Loan_Amount_Term': 'int64','ApplicantIncome': 'float64'}).dtypes

  #replacing categorical data with numbers
  final_test_df = pd.get_dummies(data = test_df, columns =['Gender','Married','Education','Self_Employed','Property_Area'] )

  final_test_df.head(20)

  final_test_df.info()

  final_test_df.astype({'Dependents': 'int64'}).dtypes

  #creating data for ML
  test_features = final_test_df.drop(['Loan_ID'], axis = 1)

  #testing the model
  #dt_predit = dt.predict(test_features)

  #rft_predict = rft.predict(test_features)
  return test_features

def split_training_data(final_train_df):
  #creating data for ML
  X = final_train_df.drop(['Loan_Status','Loan_ID'], axis = 1)
  features_col = final_train_df.drop(['Loan_Status','Loan_ID'], axis = 1)
  y = final_train_df['Loan_Status']

  y= y.astype('int')

  #splitting data into training and validation samples
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

  return X_train, X_test, y_train, y_test


def train_model(train_df):
  #call preprocessing 
  final_train_df = preprocess_train_data(train_df) 

  #call data splitter
  X_train, X_test, y_train, y_test = split_training_data(final_train_df)
  #Training decision tree classifier
  dt = DecisionTreeClassifier(criterion='entropy')
  dt.fit(X_train,y_train)

  # Trained Model Evaluation on Validation Dataset
  confidence = dt.score(X_test, y_test)
  # Validation Data Prediction
  preds = dt.predict(X_test)
  # Model Validation Accuracy
  accuracy = accuracy_score(y_test, preds)
  # Model Confusion Matrix
  conf_mat = confusion_matrix(y_test, preds)
  # Model Classification Report
  clf_report = classification_report(y_test, preds)
  print('Training Decision Tree Model')
  print(confidence)
  print('\n')
  print(accuracy)
  print('\n')
  print(conf_mat)
  print('\n')
  print(clf_report)

  # Save Trained Model
  path = './model'
  model1 = 'decsion_tree'
  dump(dt, str(path + model1 + ".joblib"))

  #Training random forest classifier
  rft = RandomForestClassifier(n_estimators=10)
  rft.fit(X_train,y_train)

  # Trained Model Evaluation on Validation Dataset
  confidence = rft.score(X_test, y_test)
  # Validation Data Prediction
  preds = rft.predict(X_test)
  # Model Validation Accuracy
  accuracy = accuracy_score(y_test, preds)
  # Model Confusion Matrix
  conf_mat = confusion_matrix(y_test, preds)
  # Model Classification Report
  clf_report = classification_report(y_test, preds)
  print('Training Decision Tree Model')
  print(confidence)
  print('\n')
  print(accuracy)
  print('\n')
  print(conf_mat)
  print('\n')
  print(clf_report)

  # Save Trained Model
  path = './model'
  model2 = 'random_forest'
  dump(rft, str(path + model2 + ".joblib"))


  #Training KNN classifier
  knn = KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)
  knn.fit(X_train,y_train)

  # Trained Model Evaluation on Validation Dataset
  confidence = knn.score(X_test, y_test)
  # Validation Data Prediction
  preds = knn.predict(X_test)
  # Model Validation Accuracy
  accuracy = accuracy_score(y_test, preds)
  # Model Confusion Matrix
  conf_mat = confusion_matrix(y_test, preds)
  # Model Classification Report
  clf_report = classification_report(y_test, preds)
  print('Training Decision Tree Model')
  print(confidence)
  print('\n')
  print(accuracy)
  print('\n')
  print(conf_mat)
  print('\n')
  print(clf_report)
  # Save Trained Model
  path = './model'
  model3 = 'knn'
  dump(knn, str(path + model3 + ".joblib"))
  return dt, rft, knn


def make_single_prediction(rft):
  myInput = []
  for i in range(0, 17):
      myInput.append(0)
  print(myInput)

  input_vals = []
  pam=['Dependents', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Gender','Married','Education','Self_Employed','Property_Area']

  count = 12
  for i in range(0,11):
    print('Enter ',pam[i])
    vals=input(':')
    count = count - 1
    #store symtoms in a list
    input_vals.append(vals)


  print(input_vals)

  my_im_dict = {}
  k = 0
  for i in input_vals:
    my_im_dict[k]= i
    k+=1

  #print(my_im_dict)

  # preprocessing user input for the machine model
  for i in range(0,len(myInput)):
      if i < 6:
        myInput[i] = my_im_dict[i]

      elif i == 6:
        if my_im_dict[i] == "Female": myInput[i] = 1
        else: myInput[i+1] = 1
        

      elif i == 7:
        if my_im_dict[i] == "No": myInput[i+1] = 1
        else: myInput[i+2] = 1
        
        

      elif i == 8:
        if my_im_dict[i] == "Graduate": myInput[i+2] = 1
        else: myInput[i+3] = 1
        
        

      elif i == 9:
        if my_im_dict[i] == "No": myInput[i+3] = 1
        else: myInput[i+4] = 1
        
        

      elif i == 10:
        
        if my_im_dict[i] == "Rural": myInput[i+4] = 1
        elif my_im_dict[i] == "Semiurban": myInput[i+5] = 1
        else: myInput[i+6] = 1

  #print(myInput)
  # Making single prediction Prediction
  input_mat = [myInput]
  predict = rft.predict(input_mat)
  print(predict[0])


dt, rft, knn = train_model(train_df)

#make_single_prediction(rft)
input_features = preprocess_test_data(test_df)
result = rft.predict(input_features)

ln_st_data=str(result)
ln_st = ln_st_data.split(" ")
ln_st.pop(0)
ln_st.pop(len(ln_st)-1)
ln_st=''.join(ln_st)
ln_st= ln_st.split('\n')
ln_st=''.join(ln_st)
ln_st=list(ln_st)

ln_st_data = [int(numeric_string) for numeric_string in ln_st]

d = {'Loan_Status': ln_st_data}
loan_st = pd.DataFrame(data=d)

test = input_features.join(loan_st)

test.to_csv("./loan_result/result.csv", encoding='utf-8', index=False)


"""
Order of input parameters
['Dependents', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 
'Credit_History', 'Gender_Female', 'Gender_Male', 'Married_No', 'Married_Yes', 'Education_Graduate', 
'Education_Not Graduate', 'Self_Employed_No', 
'Self_Employed_Yes', 'Property_Area_Rural', 'Property_Area_Semiurban', 'Property_Area_Urban'
]
"""

